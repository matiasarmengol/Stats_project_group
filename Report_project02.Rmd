---
title: "Modelling Peak Electricity Demand in Great Britain"
author: "Group 47, Matias Armengol(s2286042), Fergus Fleming(s2185709), Adi(s2278709)"
output:
  html_document:
    number_sections: no
  pdf_document:
    number_sections: no
header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{#1}}
  - \newcommand{\mat}[1]{\begin{bmatrix}#1\end{bmatrix}}
---

```{r setup, include = FALSE}
# Modify this setup code chunk to set options
# or add extra packages etc if needed.
# See the project instructions for more details
# on what code to show, and where/how.

# Set default code chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE
)

suppressPackageStartupMessages(library(tidyverse))
theme_set(theme_bw())

# To give the same random number sequence every time the document is knitted,
# making it easier to discuss the specific numbers in the text:
set.seed(12345L)
```

```{r data_cleaning, echo=FALSE}
# import data
SCS_demand_modelling <- read_csv("Project02/SCS_demand_modelling.csv")
SCS_hourly_temp <- read_csv("Project02/SCS_hourly_temp.csv")



vars <- c('Y'='demand_gross', 'Date', 'Wind'='wind', 'Solar'='solar_S', 'Temp'='temp', 'Day_Index'='wdayindex', 'Month_Index'='monthindex', 'year', 'TE')
set1 <- select(SCS_demand_modelling, vars)

set1 <- set1 |> 
  # Removing outliers using IQR method
  filter(Y >= quantile(Y, 0.25) - 1.5 * IQR(Y) & Y <= quantile(Y, 0.75) + 1.5 * IQR(Y)) |> 
  # Adding cosine transformations
  mutate(Cos_Day = cos(Day_Index)) |> 
  mutate(Cos_Month = cos(Month_Index)) |> 
  # Creating categorical variables
  mutate(week_type = factor(ifelse(Day_Index %in% c(0, 6), 0, 1), 
                            levels = c(0, 1), 
                            labels = c("Weekend", "Weekday"))) |> 
  mutate(season = factor(ifelse(Month_Index %in% c(0, 1, 10, 11), 1, 0), 
                         levels = c(0, 1), 
                         labels = c("Not Winter", "Winter")))

#convert Date from char to date
set2 <- SCS_hourly_temp
set2$Date <- as.POSIXct(set2$Date, format = "%d/%m/%Y %H:%M")

#summarize to get daily averages and variances
set2_sum <- set2 |> 
  mutate(Date = as.Date(Date)) |> 
  group_by(Date) |> 
  summarise(
    daily_avg = mean(temp),
    daily_var = var(temp),
    .groups = "drop"
  )

#merge with SCS_demand_modelling and add year_d
df <- left_join(set1, set2_sum, by = "Date")
df$year_d = abs((df$year) - 2005)
```

```{r models, echo=FALSE}
# Define M5, our chosen model
M5 <- Y ~ Solar + Wind + week_type + season + year_d + Temp + TE + daily_var
Model_M5 <- lm(M5, data = df)

```

```{r code=readLines("code.R"), eval=TRUE, echo=FALSE}
# Do not change this code chunk
# Load function definitions
source("code.R")
```


# Introduction
```{r Introduction instructions}
#This section provides a brief introduction to the task and the datasets used. The introduction is intended to be #understood by NESO analysts with a scientific background but limited statistical expertise. You can assume that the reader #of your report has read the executive summary. Briefly outline the overall approach taken in modeling future daily peak #electricity demand, describe the main steps involved, and summarize the key conclusions drawn from the analysis.
```
In this report, we aim to model the daily peak demand of electricity in Great Britain, assuming that this peak always occurs at 6pm. We are provided two data sets; SCS_demand_modelling.csv and SCS_hourly_temp. Both data sets contain information for the years from 1991 to 2005, and the months of November, December, January, February and March. The former contains general data for each day, such as gross demand, population-weighted average temperature, estimated capacity factor of wind and solar generation and date. The latter contains the hourly population-weighted average temperature for each day. Our aim is to use a linear model, with gross demand(Y) as the response variable, and a selection of covariates either chosen from the data sets, or obtained through some transformation. That is, we want a model of the form:
$$ Y_i = \beta_0 + \sum_{j=1}^m \beta_jX_j + \epsilon_i \text{, }\text{ }\text{ }\text{ } \epsilon_i \sim \mathcal{N}(0, \sigma^2),$$
where $Y_i$ is the gross demand at day $i$, and $\{X_1, \cdots, X_m\}$ is a set of covariates obtained as explained above, and $\beta_1, \cdots, \beta_m$ are the regression coefficients, and $\epsilon_i$ is the error at day $i$. The regression coefficients are chosen to minimize the root mean squared error(RMSE), given by:
$$RMSE = \sqrt{\dfrac{1}{n}\sum_{i=1}^n (\hat{y_i} - y_i)^2},$$
where y_i is is the observed gross demand at day $i$, and $\hat{y_i}$ is the gross demand predicted by the model at day $i$, given regression parameters $\beta_1, \cdots, \beta_m$, that is:
$$\hat{y_i} = \sum_{j=1}^m \beta_jx_j.$$
Choosing the regression coefficients this way ensures that the average distance between the observed gross demand and the predicted gross demand is kept as low as possible, thus reducing the uncertainty in its predictions. The main challenge of this investigation was the choice of covariates to use, thus we tested several models, with different covariates. To compare their performance, we employed a measure of the portion of total variability explained by the model, $R^2$, defined as follows:
$$R^2 = 1 - \dfrac{\sum_{i=1}^n(y_i - \hat{y_i})^2}{\sum_{i=1}^n(y_i - \bar{y})^2},$$
where $y_i$ and $\hat{y_i}$ are as defined previously, and $\hat{y}$ is the mean of all observations of the gross demand.
We then constructed a $k$-fold cross validation scheme, to assess the performance of different models on unseen data. The cross validation scheme works by splitting the observations into $k$ groups of equal size, and using one of the groups to train the model, that is to determine the regression coefficients. With the coefficients fixed, the remaining $k-1$ groups are used to test the model, computing the value of $R^2$. The process is repeated $k$ times, training the model with a different group of each time, and computing the value of $R^2$ using the remaining groups. In the next section, we explore trends in the data as well as the baseline model provided, which is used as the starting point in our analysis.

# Data description and exploratory analysis
```{r Section 2 instructions}
#Emphasis should be placed on the data features that are relevant for the subsequent modeling. Include visualizations that #help illustrate key patterns or relationships. All plots must also be described in the write up. Think carefully about #whether each plot needs to be included in your final draft. Your report should include figures and tables but they should #be as focused and impactful as possible.

#Clearly describe all preprocessing steps, including any transformations or new variables created. If the additional #dataset (`SCS_hourly_temp.csv` ) is used, provide a concise explanation of its structure and relevance to the analysis.
```

## Data visualization and preprocessing
## Baseline Model
The baseline model is the model used as a benchmark for all following models, it is given by:
$$Y_i = \beta_0 + \beta_1\text{Wind}_i + \beta_2\text{Solar}_i + \beta_3\text{temp}_i + \beta_4\text{wdayindex}_i + \beta_5\text{monthindex}_i + \epsilon_i.$$
This model does not perform well, moreover, its performance is highly dependent on the month, year and day of the observation. (ADD CROSS-VALIDATION RESULTS). This hints at the need to explore the relationship between gross demand and year, as well as refine the relationship between gross demand and "wdayindex" and "monthindex", as simply using a linear relationship for the previous two variables does not seem appropriate. 
## New variables
In light of the weaknesses of the baseline model, we have created new covariates from the dataset, by appropriate transformations of existing variables, in an attempt to better capture their relationship with gross demand. The relationship displayed in figure (ADD REFERENCE) suggests the need to make a distinction between weekends and weekdays. To do so, we created a categorical variable "week_type", defined below:
$$\text{week_type}_i = \begin{cases} 1 & \text{if } i\text{ is a weekday} \\ 0 & \text{if } i\text{ is a weekend day}\end{cases}.$$
Similarly, we created another categorical variable, "season", defined as follows:
$$\text{season}_i = \begin{cases} 0 & \text{if } i\text{ is in March} \\ 1 & \text{otherwise}\end{cases},$$
as figure (ADD REFERENCE) shows that gross demand in March differs significantly from any other month. Figure (ADD REFERENCE) indicates that a linear relationship between gross demand and year is not suitable. As a result, we constructed a new variable instead, "year_d" to model the dependence of gross demand on the year, this was defined as follows:
$$\text{year}_{d_i} = |\text{year}_i - 2005|.$$
Finally, to capture the effects of the variability of the temperature in a given day, we defined the variable "daily_var", as displayed below:
$$\text{daily_var}_i = \widehat{Var}(\text{temp}_i) = .$$
This information was extracted from the "SCS_hourly_temp" dataset, and $ \widehat{Var}(\text{temp}_i)$ is the estimated variance of all hourly temperature measurements from day $i$. The use of this dataset provides further insight of the relationship between gross demand and temperature, allowing our model to predict the former more accurately than if we had used temperature alone.

# Model fitting and cross-validation results
```{r Section 3 intsructions}
#In this section you should detail your choice of model and describe the process used to refine and fit the model. You are #encouraged to explore different models methods but you should not include a detailed narrative of all of these attempts. #For instance, you can mention the approaches you tried tried and include a comparison but do not add in depth discussions #of these models beyond why they were rejected. This section should mention the methods explored and why they were #rejected, but most of your effort should go into describing the model you are using and your process for tuning and #validating it.

#Provide implementation details and include results from cross-validation or other model evaluation techniques, #highlighting improvements and any trade-offs.
```

## Model overview
We are now ready to introduce our model, which builds on the baseline model, while incorporating the new variables defined in the previous section, as following:
$$Y_i = \beta_0 + \beta_1\text{Wind}_i + \beta_2\text{Solar}_i + \beta_3\text{temp}_i + \beta_4\text{week_type}_i + \beta_5\text{season}_i + \beta_6\text{year_d}_i + \beta_7\text{TE}_i + \beta_8\text{daily_var}_i + \epsilon_i.$$
This model performs better than all most other models we have tested, with the main trade off being its increased complexity. To select this model, we have tested several variations including the use of different variables, or transformations of the variables. Although slightly better results were obtained for some models, for example by implementing a dependency on the cubic root of the temperature, they were ultimately discarded, as the slight improvement in prediction accuracy was not enough to justify the significant increase in model complexity.
## Model performance

## Compare winter
We investigated the variation in maximum demand over the winter of 2013/14, with the weather conditions from previous winters.

The function 'compare_winter' has been written for this task. We begin by selecting the data from the desired winter season. Then, we replace the year column with 2013/14 as appropriate, before redefining all of the year-dependent variables ('year_d, week_type') based upon this. Using the 'predict()' function from base R, we then predict the total demand over this fictional winter season before extracting and returning the maximum value that the model attains.

  
```{r compare_winter_plots, echo=FALSE, message=FALSE}
source("code_modular.R")

years <- 1991:2012

comparisons <- lapply(years, function(year) {
  compare_winter(Model_M5, df, year)
})

comparisons_df <- data.frame(
  other_year = years,
  control_max = sapply(comparisons, function(x) x$control_max),
  max_predicted = sapply(comparisons, function(x) x$max_predicted)
)

comparisons_df <- mutate(comparisons_df, diff = (control_max - max_predicted))

# Plot 1: Predicted Max Demand
ggplot(data = comparisons_df, aes(x = other_year, y = max_predicted)) +
  geom_point() +
  geom_smooth(method = "loess", se = TRUE, color = "red") + # Added loess smoothing and removed standard error
  labs(
    title = "Predicted Max Demand If 2013/14 Had Another Winter's Weather",
    x = "Year Used for Weather Conditions",
    y = "Predicted Max Demand"
  ) +
  theme_minimal()

# Plot 2: Predicted Difference
ggplot(data = comparisons_df, aes(x = other_year, y = diff)) +
  geom_point() +
  geom_smooth(method = "loess", se = TRUE, color = "blue") + # Added loess smoothing and removed standard error
  labs(
    title = "Predicted Difference in Max Demand If 2013/14 Had Another Winter's Weather",
    x = "Year Used for Weather Conditions",
    y = "Difference in Max Demand (Predicted - Actual)"
  ) +
  theme_minimal()
```
These plots above depict both the predicted demand itself and the difference between it and the observed conditions in 2013/14.\\
The observed maximum demand over the winter of 2013/14 was $5243MW$. From the difference plot, we can see that the difference is typically negative - most years' weather conditions would decrease the demand over the winter, our model predicts. We do see that there are several cases where the difference is positive, and that the predicted demand is higher than observed. However, the average difference is $-262MW$ to the nearest $MW$. \\
A qualitative interpretation of this is that 2013/14 had a particularly cold winter, or one that increased demand for some other factors. We can check directly what the average temperature in the winter of 2013/14.

```{r check_temp, include=FALSE}

winter_set <- df |> 
    filter((year == "2013" & Month_Index %in% c(10, 11)) | (year == "2014" & Month_Index %in% c(0, 1, 2)))
 this_average <- mean(winter_set$Temp)
 
all_average <- mean(df$Temp)

print(this_average)
print(all_average)

```


# Conclusion
```{r section 4 instructions}
#Summarize here the key insights from your analysis, focusing on the final model’s predictive performance, reliability, and #practical relevance for NESO. Discuss the importance of the selected covariates, as well as any observed limitations or #assumptions that should be considered when applying the model in practice.

#Emphasize how your model can support NESO's long-term planning goals. If the model underperforms in some respects, provide #a clear and well-reasoned explanation. Keep in mind that a negative result, i.e. a model that does not work well #predictively, that is well explained and justified in terms of why it failed will likely receive higher marks than a model #with strong predictive performance but with poor or incorrect explanations and justifications. In other words, sound #reasoning and transparency will be valued more than overclaiming results.
```


# Code Appendix
```{r section 5 instructions}
#Include here all the code used in your analysis. Ensure that the code is well-commented so it is easy to follow and reuse.
```


```{r code=readLines("code.R"), eval=FALSE, echo=TRUE}
# Do not change this code chunk
```

