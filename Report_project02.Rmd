---
title: "Modelling Peak Electricity Demand in Great Britain"
subtitle: "Word count: 2,345 words"
author: "Group 47, Matias Armengol(s2286042), Fergus Fleming(s2185709), Adithya Kumar(s2278709)"
output:
  html_document:
    number_sections: no
  pdf_document:
    number_sections: no
header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{#1}}
  - \newcommand{\mat}[1]{\begin{bmatrix}#1\end{bmatrix}}
---

```{r setup, include=FALSE, echo=FALSE}

# Set default code chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE
)

library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(lubridate)
library(caret)

suppressPackageStartupMessages(library(tidyverse))
theme_set(theme_bw())

# To give the same random number sequence every time the document is knitted,
# making it easier to discuss the specific numbers in the text:
set.seed(12345L)
```

```{r data_cleaning, include = FALSE, echo=FALSE}
# import data
SCS_demand_modelling <- read_csv("Project02/SCS_demand_modelling.csv")
SCS_hourly_temp <- read_csv("Project02/SCS_hourly_temp.csv")

vars <- c('Y'='demand_gross', 'Date', 'Wind'='wind', 'Solar'='solar_S', 'Temp'='temp', 'Day_Index'='wdayindex', 'Month_Index'='monthindex', 'year', 'TE')
set1 <- select(SCS_demand_modelling, vars)

set1 <- set1 |> 
  # Removing outliers using IQR method
  filter(Y >= quantile(Y, 0.25) - 1.5 * IQR(Y) & Y <= quantile(Y, 0.75) + 1.5 * IQR(Y)) |> 

  # Creating categorical variables
  mutate(is_weekday = factor(ifelse(Day_Index %in% c(0, 6), 0, 1), 
                            levels = c(0, 1), 
                            labels = c("Weekend", "Weekday"))) |> 
  mutate(is_winter = factor(ifelse(Month_Index %in% c(0, 1, 10, 11), 1, 0), 
                         levels = c(0, 1), 
                         labels = c("Not Winter", "Winter")))

#convert Date from char to date
set2 <- SCS_hourly_temp
set2$Date <- as.POSIXct(set2$Date, format = "%d/%m/%Y %H:%M")

#summarize to get daily averages and variances
set2_sum <- set2 |> 
  mutate(Date = as.Date(Date)) |> 
  group_by(Date) |> 
  summarise(
    daily_avg = mean(temp),
    daily_var = var(temp),
    .groups = "drop"
  )

#merge with SCS_demand_modelling and add year_d
df <- left_join(set1, set2_sum, by = "Date")
df$year_d = abs((df$year) - 2005)
```

```{r models, echo=FALSE}
# Define the baseline model M0
M0 <- Y ~ Wind + Solar + Temp + Day_Index + Month_Index
Model_M0 <- lm(M0, data = df)

# Define M5, our chosen model
M5 <- Y ~ Solar + Wind + is_weekday + is_winter + year_d + Temp + TE + daily_var
Model_M5 <- lm(M5, data = df)

```

```{r code=readLines("code.R"), eval=TRUE, echo=FALSE}
# Do not change this code chunk
# Load function definitions
source("code.R")
```


# Introduction
In this report, we aim to model the daily peak demand of electricity in Great Britain. We are provided two data sets; "SCS_demand_modelling.csv" and "SCS_hourly_temp". Both data sets contain information for the years from 1991 to 2005, and the months of November, December, January, February and March. The former contains general data for each day, such as gross demand, recorded at 6pm, population-weighted average temperature, estimated capacity factor of wind and solar generation and date. The latter contains the hourly population-weighted average temperature for each day. Throughout our analysis we assume that daily demand peaks at 6pm, thus allowing us to use the gross demand variable and peak gross demand interchangeably. Our aim is to use a linear model, with gross demand(Y) as the response variable, and a selection of covariates either chosen from the data sets, or obtained through some transformation. That is, we want a model of the form:
$$ Y_i = \beta_0 + \sum_{j=1}^m \beta_jX_j + \epsilon_i \text{, }\text{ }\text{ }\text{ } \epsilon_i \sim \mathcal{N}(0, \sigma^2),$$
where $Y_i$ is the gross demand at day $i$, and $\{X_1, \cdots, X_m\}$ is a set of covariates obtained as explained above, and $\beta_1, \cdots, \beta_m$ are the regression coefficients, and $\epsilon_i$ is the error at day $i$. The regression coefficients are chosen to minimize the root mean squared error ($RMSE$), given by:
$$RMSE = \sqrt{\dfrac{1}{n}\sum_{i=1}^n (\hat{y_i} - y_i)^2},$$
where $y_i$ is is the observed gross demand at day $i$, and $\hat{y_i}$ is the gross demand predicted by the model at day $i$, given regression parameters $\beta_1, \cdots, \beta_m$, that is:
$$\hat{y_i} = \sum_{j=1}^m \beta_jx_j.$$
Choosing the regression coefficients this way ensures that the average distance between the observed gross demand and the predicted gross demand is kept as low as possible, thus reducing the uncertainty in its predictions. The main challenge of this investigation was the choice of covariates to use, thus we tested several models, with different covariates. To compare their performance, we employed a measure of the portion of total variability explained by the model, $R^2$, defined as follows:
$$R^2 = 1 - \dfrac{\sum_{i=1}^n(y_i - \hat{y_i})^2}{\sum_{i=1}^n(y_i - \bar{y})^2},$$
where $y_i$ and $\hat{y_i}$ are as defined previously, and $\hat{y}$ is the mean of all observations of the gross demand.
We then constructed a $k$-fold cross validation scheme, to assess the performance of different models on unseen data. The cross validation scheme works by splitting the observations into $k$ groups of equal size, and using one of the groups to train the model, that is to determine the regression coefficients. With the coefficients fixed, the remaining $k-1$ groups are used to test the model, computing the value of $R^2$. The process is repeated $k$ times, training the model with a different group of each time, and computing the value of $R^2$ using the remaining groups. Our analysis provides a solid final model, that is able to explain a large portion of the variability in the data. We deduce that the variables given are enough to provide a satisfactory model, however a more accurate and reliable model could be obtained by having access to a more complete dataset, with a greater range of the data collected, as well as the inclusion of more variables, that may be influencing gross demand but are not captured by the variables provided. In the next section, we explore trends in the data as well as the baseline model provided, which is used as the starting point in our analysis.

# Data description and exploratory analysis

## Data visualization and pre-processing
To prepare our data for analysis, we began by dropping unneeded coefficients. This was a list that changed over the course of our improvements on our candidate model, as we made informed changes to our model versions. Below is an initial covariate matrix that we used to get an overview of which columns could provide information on our response variable.

```{r covariate_matrix, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 1: Correletion matrix for all variables in the dataset SCS_demand_modelling.csv.'}
numeric_vars <- SCS_demand_modelling %>%
  select(-1, -Date)

#Correlation matrix
cor_matrix <- cor(numeric_vars, use = "pairwise.complete.obs")

# Create a more readable table with rounded values
cor_table <- round(cor_matrix, 3)

# Reshape the correlation matrix for ggplot
cor_data <- melt(cor_matrix)

# Create heat-map with ggplot2
heatmap <- ggplot(data = cor_data, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                        midpoint = 0, limit = c(-1,1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_fixed() +
  geom_text(aes(label = round(value, 2)), size = 3) +
  labs(title = "Correlation Matrix for Demand Variables",
       x = "", y = "")

heatmap

```
<div style="height: 10px;"></div>
Firstly what we see from this plot is that there are many variables that have exceptionally high correlation. Inspecting which pairs these are, we observe that many of these are defined as transformations of one another, which explains their exceptionally high correlation. A major example of this is the "TO" and "TE" relationship.

We can see that the "year" variable has a moderate positive correlation to "demand_gross", and both "TO" and "TE" have a moderate negative correlation. These are some examples of how we might choose candidate models in order to improve upon the baseline model. 
The following plots; Figure (2), Figure (3), Figure (4) and Figure (5) provide insight on the precise nature of the relationship between gross demand and year, month, day and temperature respectively. These plots were instrumental in informing our choice of model.

```{r demand_vs_year, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figre 2: Plot of average yearly gross demand against year, highlighting their non-linear relationship.'}
SCS_demand_modelling <- SCS_demand_modelling %>%
  mutate(Date = as.Date(Date, format = "%Y-%m-%d"))

# Aggregate data for yearly average
demand_yearly <- SCS_demand_modelling %>%
  group_by(year) %>%
  summarise(avg_demand = mean(`demand_gross`, na.rm = TRUE))

# Plot: Yearly Average Gross Demand vs. Year
ggplot(demand_yearly, aes(x = year, y = avg_demand)) +
  geom_point(color = "darkblue") +
  geom_smooth(color = "darkred") +
  labs(title = "Yearly Average Gross Demand vs. Year",
       x = "Year", y = "Average Gross Demand (MW)") +
  theme_minimal()
```
<div style="height: 10px;"></div>
From the plot presented above, we observe a strong relationship between the year and the average yearly gross demand. We plotted average gross demand as solely a function of year, thus we initially conjectured some cyclical or polynomial relationship. However, the plot we observe here is sufficient for us to confidently include year as a covariate in our candidate models going forwards.

```{r demand_vs_month, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 3: Bar plot of average monthly gross demand against month, for the months of January(0), February(1), March(2), November(10) and December(11). This highlights the significant difference between March and the other months.'}

SCS_demand_modelling %>%
  group_by(monthindex) %>%
  summarize(avg_demand = mean(demand_gross, na.rm = TRUE)) %>%
  ggplot(aes(x = monthindex, y = avg_demand)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  labs(title = "Average Demand by Month",
       x = "Month Index", y = "Average Demand")
```
<div style="height: 10px;"></div>
As the number of data points on the month scale was sufficiently low, in the previous plot we chose to use a bar plot instead of treating the time scale as continuous.

The most visible result here is the difference between the month of March and the other months, with the month of March exhibiting lower average monthly gross demand than the other months. Qualitatively we can expect this, as March would be expected to be different in terms of weather to the other months for which we have data. It is reasonable to expect this to translate into a lower gross demand during this time.

```{r demand_vs_day, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 4: Bar plot of average gross demand against day, for the days of the week, that is Sunday(0), Monday(1), Tuesday(2), Wednesday(3), Thursday(4), Friday(5) and Saturday(6). This highlights the difference between weekend days(Sunday and Saturday) and the other days.'}
SCS_demand_modelling %>%
  group_by(wdayindex) %>%
  summarize(avg_demand = mean(demand_gross, na.rm = TRUE)) %>%
  ggplot(aes(x = wdayindex, y = avg_demand)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  labs(title = "Average Demand by Day of Week",
       x = "Day of Week Index", y = "Average Demand")
```
<div style="height: 10px;"></div>
Similarly to the month case, the above plot shows that there is a noticeable difference between the average gross demand of weekend days and weekdays. This is expected, as during weekends energy demand towards office lighting and heating, as well as commuting is lower, as a significant portion of the population does not work. 

```{r temp_demand, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 5: Scatter plot of gross demand against population weighted average tmeperature, showing a significant negative correlation.'}
ggplot(SCS_demand_modelling, aes(x = temp, y = demand_gross)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  theme_minimal() +
  labs(title = "Relationship Between Temperature and Demand",
       x = "Temperature", y = "Gross Demand")

```
<div style="height: 10px;"></div>
A reasonable assumption would be to expect energy demand to decrease with temperature, as the energy required to heat homes is reduced. Indeed the plot above supports this intuition, showing a negative correlation, although relatively weak between the two variables.

## Baseline model
The baseline model is the model used as a benchmark for all following models, it is given by:
$$Y_i = \beta_0 + \beta_1\text{wind}_i + \beta_2\text{solar}_i + \beta_3\text{temp}_i + \beta_4\text{wdayindex}_i + \beta_5\text{monthindex}_i + \epsilon_i.$$
This model does not perform well, moreover, its performance is highly dependent on the month, year and day of the observation. Its unreliability when predicting from different months is evident in Figure (6), Figure (7) and Figure (8), showing significantly worse predictions for the month of March. This hints at the need to explore the relationship between gross demand and "year", as well as refine the relationship between gross demand and "wdayindex" and "monthindex", as simply using a linear relationship for the previous two variables does not seem appropriate.

## New variables
In light of the weaknesses of the baseline model, we have created new covariates from the dataset, by appropriate transformations of existing variables, in an attempt to better capture their relationship with gross demand. The relationship displayed in Figure (4) suggests the need to make a distinction between weekends and weekdays. To do so, we created a categorical variable "is_weekday", defined below:
$$\text{is_weekday}_i = \begin{cases} 1 & \text{if } i\text{ is a weekday} \\ 0 & \text{if } i\text{ is a weekend day}\end{cases}.$$
Similarly, we created another categorical variable, "is_winter", defined as follows:
$$\text{is_winter}_i = \begin{cases} 0 & \text{if } i\text{ is in March} \\ 1 & \text{otherwise}\end{cases},$$
as Figure (3) shows that gross demand in March differs significantly from any other month. Figure (2) indicates that a linear relationship between gross demand and year is not suitable. As a result, we constructed a new variable instead, "year_d" to model the dependence of gross demand on the year, this was defined as follows:
$$\text{year_d}_{i} = |\text{year}_i - 2005|.$$
Finally, to capture the effects of the variability of the temperature in a given day, we defined the variable "daily_var", as displayed below:
$$\text{daily_var}_i = \widehat{Var}(\text{temp}_i) = \dfrac{1}{23}\sum_{j=1}^{24}(\text{temp}_{i,j} - \overline{\text{temp}_i})^2 .$$
This information was extracted from the "SCS_hourly_temp" dataset, and $\widehat{Var}(\text{temp}_i)$ is the estimated variance of all hourly temperature measurements from day $i$, $\overline{\text{temp}_i}$ is the average hourly temperature of day $i$, and $\text{temp}_{i,j}$ is the temperature recorded at day $i$ and hour $j$. The use of this dataset provides further insight of the relationship between gross demand and temperature, allowing our model to predict the former more accurately than if we had used temperature alone.

# Model fitting and cross-validation results

## Model overview
We are now ready to introduce our model, which builds on the baseline model, while incorporating the new variables defined in the previous section, as following:
$$Y_i = \beta_0 + \beta_1\text{Wind}_i + \beta_2\text{Solar}_i + \beta_3\text{temp}_i + \beta_4\text{is_weekday}_i + \beta_5\text{is_winter}_i + \beta_6\text{year_d}_i + \beta_7\text{TE}_i + \beta_8\text{daily_var}_i + \epsilon_i.$$
The model was fit using the "lm" built in function, which takes parameters "formula", which specifies the form of the linear model, in our case simply $Y \sim \text{Solar} + \text{Wind} + \text{week_type} + \text{season} + \text{year_d} + \text{Temp} + \text{TE} + \text{daily_var}$, and "data", which specifies which set of observations should be used to fit the model. The function then fits the model by computing the regression coefficients that minimize the value of $R^2$, as explained in the introduction.
This model performs better than most of the other models we have tested, with the main trade off being its increased complexity. To select this model, we have tested several variations including the use of different variables, or transformations of the variables. Although slightly better results were obtained for some models, for example by implementing a dependency on the cubic root of the temperature, justified by Figure (5), they were ultimately discarded, as the slight improvement in prediction accuracy was not enough to justify the significant increase in model complexity.

## Model performance
```{r base_cross_validation, echo=FALSE}
source("code.R")

M0_cv <- k_fold_cross_validate(Model_M0, df, strat_vars = c("is_weekday", "is_winter"))
M5_cv <- k_fold_cross_validate(Model_M5, df, strat_vars = c("is_weekday", "is_winter"))
```

We use the function "k_fold_cross_validation()" to assess our model performance. The function works by splitting our data into k disjoint groups called 'folds'. Crucially because we have categorical variables present, we use stratified k-fold cross validation, which means that we keep the relative frequencies of each category present within each fold. This ensures that no fold is left with only one category level, and therefore the model may always arrive at a coefficient for the categorical variable.

We then assess the model's performance via $RMSE$, $R^2$ and $adj-R^2$ across all remaining $k-1$ folds. This value is then stored, and the process is repeated with the model being refitted on each of the $k$ folds. The average of each of these metrics is computed and returned in the output of the function. 

For the baseline model discussed earlier, we note these key metrics. The overall adjusted $R^2$ metric is 0.068, which decreases slightly to 0.061 for the average $adj-R^2$ over each of our 5 folds. This model does not explain very much of the variation in the gross demand and therefore there is a lot of room for improvement.

Our final model has an overall adjusted $R^2$ of 0.762 and a 5-fold-average of 0.758. The plots below compare these figures as well as the RMSE of each model. 

```{r compare_metrics, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap= 'Figure 6: A plot comparing three key performance metrics of the baseline and final models.'}


#make a dataframe from the output of the cross-validation function
overall_metrics <- data.frame(
  metric = c("RMSE", "R^2", "Adjusted R^2"),
  M0 = c(4824.76, 0.066, 0.060), # add values manually because function output is strange and just 3 values
  M5 = c(2434.37, 0.762, 0.759)
)

# pivot longer for ggplot
overall_long <- overall_metrics %>%
  pivot_longer(cols = c(M0, M5), names_to = "model", values_to = "value")

# flatten the output for easier extraction
flatten_cv_results <- function(results, model_name) {
  # Extract month performance metrics
  month_metrics <- results$month_performance
  
  # Create empty lists to store data
  month_list <- character()
  metric_type <- character()
  metric_value <- numeric()
  model <- character()
  
  # Loop through each month
  for (month_key in names(month_metrics)) {
    # Extract month name
    month_name <- sub("month_", "", month_key)
    
    # Get metrics for this month
    metrics <- month_metrics[[month_key]]
    
    # Add each metric to our lists
    for (metric_name in names(metrics)) {
      month_list <- c(month_list, month_name)
      metric_type <- c(metric_type, metric_name)
      metric_value <- c(metric_value, metrics[[metric_name]])
      model <- c(model, model_name)
    }
  }
  
  # Create data frame
  df <- data.frame(
    month = month_list,
    metric = metric_type,
    value = metric_value,
    model = model,
    stringsAsFactors = FALSE
  )
  
  return(df)
}

# facet the plot so we can have different scales 
p1_faceted <- overall_long %>%
  ggplot(aes(x = model, y = value, fill = model)) +
  geom_bar(stat = 'identity', position = position_dodge(width = 0.9), width = 0.8) +
  scale_fill_manual(values = c("M0" = "darkred", "M5" = "#82ca9d")) +
  facet_wrap(~ metric, scales = "free_y") +
  theme_minimal() +
  labs(title = "M0 vs M5 Model Performance Comparison",
       subtitle = "Overall Performance Metrics",
       x = "",
       y = "Value",
       fill = "Model") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5),
        strip.background = element_rect(fill = "lightgray", color = NA),
        strip.text = element_text(face = "bold"))

p1_faceted

```

```{r monthly_rmse, echo=FALSE, fig.align='center', fig.cap='Figure 7: Monthly RMSE between the baseline and final models.'}
# Define the months in order
month_keys <- c("month_11", "month_12", "month_01", "month_02", "month_03")
month_names <- c("November", "December", "January", "February", "March")

# Extract metrics using sapply
M0_RMSE <- sapply(month_keys, function(m) M0_cv$month_performance[[m]]$rmse)
M5_RMSE <- sapply(month_keys, function(m) M5_cv$month_performance[[m]]$rmse)
M0_R2 <- sapply(month_keys, function(m) M0_cv$month_performance[[m]]$r2)
M5_R2 <- sapply(month_keys, function(m) M5_cv$month_performance[[m]]$r2)

# Create the data frame
month_data <- data.frame(
  month = factor(month_names, levels = month_names),
  M0_RMSE = M0_RMSE,
  M5_RMSE = M5_RMSE,
  M0_R2 = M0_R2,
  M5_R2 = M5_R2
)

# make month a factor variable
month_data$month <- factor(month_data$month, 
                          levels = c("November", "December", "January", "February", "March"))

# pivot for ggplot
month_rmse_long <- month_data %>%
  select(month, M0_RMSE, M5_RMSE) %>%
  pivot_longer(cols = c(M0_RMSE, M5_RMSE), 
               names_to = "model", 
               values_to = "RMSE") %>%
  mutate(model = gsub("_RMSE", "", model))

# Plot monthly RMSE
p2 <- ggplot(month_rmse_long, aes(x = month, y = RMSE, fill = model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  geom_text(aes(label = sprintf("%.0f", RMSE)),
            position = position_dodge(width = 0.9), vjust = -0.5, size = 3.2) +
  scale_fill_manual(values = c("M0" = "darkred", "M5" = "#82ca9d")) +
  theme_minimal() +
  labs(title = "Monthly Performance (RMSE)",
       x = "",
       y = "RMSE",
       fill = "Model") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1))

p2
```


```{r monthly_r^2, echo=FALSE, fig.align='center', fig.cap='Figure 8: Monthly R-squared between the baseline and final models.'}
# pivot for ggplot
month_r2_long <- month_data %>%
  select(month, M0_R2, M5_R2) %>%
  pivot_longer(cols = c(M0_R2, M5_R2), 
               names_to = "model", 
               values_to = "R2") %>%
  mutate(model = gsub("_R2", "", model))

# Plot
p3 <- ggplot(month_r2_long, aes(x = month, y = R2, fill = model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  geom_text(aes(label = sprintf("%.3f", R2)),
            position = position_dodge(width = 0.9), vjust = ifelse(month_r2_long$R2 < 0, 1.5, -0.5), size = 3.2) +
  scale_fill_manual(values = c("M0" = "darkred", "M5" = "#82ca9d")) +
  theme_minimal() +
  labs(title = "Monthly Performance (R^2)",
       x = "",
       y = "R^2",
       fill = "Model") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(-0.2, 1)

p3
```
The above plots, highlight a significant weakness of our model: Its predictions are significantly worse for the month of December. This is probably attributed to factors that are not captured in our observations, such as holidays and transportation costs from increased travelling, as well as decreased electricity demand from office buildings. 

## Compare winter
We investigated the variation in maximum demand over the winter of 2013/14, with the weather conditions from previous winters.

The function 'compare_winter' has been written for this task. We begin by selecting the data from the desired winter season. Then, we replace the year column with 2013/14 as appropriate, before redefining all of the time-dependent variables ('year_d', 'is_weekday') based upon this. Using the 'predict()' function from base R, we then predict the total demand over this fictional winter season before extracting and returning the maximum value that the model attains.

  
```{r compare_winter_plot_1, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 9: How maximum demand is projected to vary with weather conditions from previous years.'}
source("code_modular.R")

years <- 1991:2012

comparisons <- lapply(years, function(year) {
  compare_winter(Model_M5, df, year)
})

comparisons_df <- data.frame(
  other_year = years,
  control_max = sapply(comparisons, function(x) x$control_max),
  max_predicted = sapply(comparisons, function(x) x$max_predicted)
)

comparisons_df <- mutate(comparisons_df, diff = (control_max - max_predicted))

# Plot 1: Predicted Max Demand
ggplot(data = comparisons_df, aes(x = other_year, y = max_predicted)) +
  geom_point() +
  geom_smooth(method = "loess", se = TRUE, color = "red") + # Added loess smoothing and removed standard error
  labs(
    title = "Predicted Max Demand If 2013/14 Had Another Winter's Weather",
    x = "Year Used for Weather Conditions",
    y = "Predicted Max Demand"
  ) +
  theme_minimal()
```
<div style="height: 10px;"></div>
```{r compare_winter_plot_2, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 10: How the difference between projected maximum demand and observed maximum demand varies with weather conditions from previous years.'}
# Plot 2: Predicted Difference
ggplot(data = comparisons_df, aes(x = other_year, y = diff)) +
  geom_point() +
  geom_smooth(method = "loess", se = TRUE, color = "blue") + # Added loess smoothing and removed standard error
  labs(
    title = "Predicted Difference in Max Demand If 2013/14 Had Another Winter's Weather",
    x = "Year Used for Weather Conditions",
    y = "Difference in Max Demand (Predicted - Actual)"
  ) +
  theme_minimal()
```
<div style="height: 10px;"></div>
These plots above depict both the predicted demand itself and the difference between it and the observed conditions in 2013/14.

The observed maximum demand over the winter of 2013/14 was 5243MW. From the difference plot, we can see that the difference is typically negative - most years' weather conditions would decrease the demand over the winter, our model predicts. We do see that there are several cases where the difference is positive, and that the predicted demand is higher than observed. However, the average difference is -262MW to the nearest MW.

A qualitative interpretation of this is that 2013/14 had a winter that caused an increase in demand for some number of factors. A reasonable first assumption could be that there was a lower average during this winter. We can check directly what the average temperature in the winter of 2013/14.

```{r check_temp, include=FALSE}

winter_set <- df |> 
    filter((year == "2013" & Month_Index %in% c(10, 11)) | (year == "2014" & Month_Index %in% c(0, 1, 2)))
 this_average <- mean(winter_set$Temp)
 
all_average <- mean(df$Temp)

print(this_average)
print(all_average)

```
Taking the average temperature over the 2013/14 winter we get 5.60 degrees (2dp.), as opposed to 4.77 degrees (2dp.) over the entire set. This is contrasting to our assumption, but there could be many reasons as to why the demand happened to be higher. This could be a potential limitation of the model. These are discussed below.

# Conclusion

Overall, our model performs well, and it achieves equally strong predictions in different time periods, with prediction accuracy being similar across all months and days of the week. A main limitation of the model is the relationship chosen between gross demand and "year". This is because the average yearly gross demand seems to increase steadily from 1991 to 2005, and then starts steadily dropping after 2005. The fact that the model was trained on only 10 years of data after 2005, makes it difficult to predict how the average yearly gross demand will behave in subsequent years. It could for example, start increasing again, thus making the period from 2005 to 2015 simply an exception to an otherwise linear trend. It could also be that the pattern is periodic, driven by the periodic nature of the economy. At the end we decided that average yearly gross demand is likely to continue dropping, driven by factors such as increased environmental awareness, increased availability and efficiency of renewable, non centralized sources and declining population growth. However the accuracy of our model's predictions in future years is strongly dependent on this relationship, which we cannot predict with confidence with the data given. As a result, the model's predictions are likely to become less accurate as the year of the observation strays further away from 2015. However, as long as the year of the observation is not too far from 2015, we expect the model to provide valuable and accurate insight on the gross demand. This means that our model will allow NESO to accurately predict future gross demand, provided that the model is not being used too far into the future(after 2015), allowing them to anticipate future changes in demand, and efficiently plan and allocate resources to ensure that the gross demand is reliably met. 

# Code Appendix
In this section, we provide the documentation for all the functions created and used in this report.

```{r code=readLines("code.R"), eval=FALSE, echo=TRUE}
# Do not change this code chunk
```

