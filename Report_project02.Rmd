---
title: "Modelling Peak Electricity Demand in Great Britain"
author: "Group 47, Matias Armengol(s2286042), Fergus Fleming(s2185709), Adithya Kumar(s2278709)"
output:
  html_document:
    number_sections: no
  pdf_document:
    number_sections: no
header-includes:
  - \newcommand{\bm}[1]{\boldsymbol{#1}}
  - \newcommand{\mat}[1]{\begin{bmatrix}#1\end{bmatrix}}
---

```{r setup, include=FALSE, echo=FALSE}
# Modify this setup code chunk to set options
# or add extra packages etc if needed.
# See the project instructions for more details
# on what code to show, and where/how.

# Set default code chunk options
knitr::opts_chunk$set(
  echo = TRUE,
  eval = TRUE
)

library(readr)
library(dplyr)
library(tidyr)
library(ggplot2)
library(reshape2)
library(lubridate)
library(caret)

suppressPackageStartupMessages(library(tidyverse))
theme_set(theme_bw())

# To give the same random number sequence every time the document is knitted,
# making it easier to discuss the specific numbers in the text:
set.seed(12345L)
```

```{r data_cleaning, include = FALSE, echo=FALSE}
# import data
SCS_demand_modelling <- read_csv("Project02/SCS_demand_modelling.csv")
SCS_hourly_temp <- read_csv("Project02/SCS_hourly_temp.csv")



vars <- c('Y'='demand_gross', 'Date', 'Wind'='wind', 'Solar'='solar_S', 'Temp'='temp', 'Day_Index'='wdayindex', 'Month_Index'='monthindex', 'year', 'TE')
set1 <- select(SCS_demand_modelling, vars)

set1 <- set1 |> 
  # Removing outliers using IQR method
  filter(Y >= quantile(Y, 0.25) - 1.5 * IQR(Y) & Y <= quantile(Y, 0.75) + 1.5 * IQR(Y)) |> 

  # Creating categorical variables
  mutate(is_weekday = factor(ifelse(Day_Index %in% c(0, 6), 0, 1), 
                            levels = c(0, 1), 
                            labels = c("Weekend", "Weekday"))) |> 
  mutate(is_winter = factor(ifelse(Month_Index %in% c(0, 1, 10, 11), 1, 0), 
                         levels = c(0, 1), 
                         labels = c("Not Winter", "Winter")))

#convert Date from char to date
set2 <- SCS_hourly_temp
set2$Date <- as.POSIXct(set2$Date, format = "%d/%m/%Y %H:%M")

#summarize to get daily averages and variances
set2_sum <- set2 |> 
  mutate(Date = as.Date(Date)) |> 
  group_by(Date) |> 
  summarise(
    daily_avg = mean(temp),
    daily_var = var(temp),
    .groups = "drop"
  )

#merge with SCS_demand_modelling and add year_d
df <- left_join(set1, set2_sum, by = "Date")
df$year_d = abs((df$year) - 2005)
```

```{r models, echo=FALSE}
# Define the baseline model M0
M0 <- Y ~ Wind + Solar + Temp + Day_Index + Month_Index
Model_M0 <- lm(M0, data = df)

# Define M5, our chosen model
M5 <- Y ~ Solar + Wind + is_weekday + is_winter + year_d + Temp + TE + daily_var
Model_M5 <- lm(M5, data = df)

```

```{r code=readLines("code.R"), eval=TRUE, echo=FALSE}
# Do not change this code chunk
# Load function definitions
source("code.R")
```


# Introduction
```{r Introduction instructions, echo = FALSE}
#This section provides a brief introduction to the task and the datasets used. The introduction is intended to be #understood by NESO analysts with a scientific background but limited statistical expertise. You can assume that the reader #of your report has read the executive summary. Briefly outline the overall approach taken in modeling future daily peak #electricity demand, describe the main steps involved, and summarize the key conclusions drawn from the analysis.
```
In this report, we aim to model the daily peak demand of electricity in Great Britain, assuming that this peak always occurs at 6pm. We are provided two data sets; "SCS_demand_modelling.csv" and "SCS_hourly_temp". Both data sets contain information for the years from 1991 to 2005, and the months of November, December, January, February and March. The former contains general data for each day, such as gross demand, population-weighted average temperature, estimated capacity factor of wind and solar generation and date. The latter contains the hourly population-weighted average temperature for each day. Our aim is to use a linear model, with gross demand(Y) as the response variable, and a selection of covariates either chosen from the data sets, or obtained through some transformation. That is, we want a model of the form:
$$ Y_i = \beta_0 + \sum_{j=1}^m \beta_jX_j + \epsilon_i \text{, }\text{ }\text{ }\text{ } \epsilon_i \sim \mathcal{N}(0, \sigma^2),$$
where $Y_i$ is the gross demand at day $i$, and $\{X_1, \cdots, X_m\}$ is a set of covariates obtained as explained above, and $\beta_1, \cdots, \beta_m$ are the regression coefficients, and $\epsilon_i$ is the error at day $i$. The regression coefficients are chosen to minimize the root mean squared error(RMSE), given by:
$$RMSE = \sqrt{\dfrac{1}{n}\sum_{i=1}^n (\hat{y_i} - y_i)^2},$$
where y_i is is the observed gross demand at day $i$, and $\hat{y_i}$ is the gross demand predicted by the model at day $i$, given regression parameters $\beta_1, \cdots, \beta_m$, that is:
$$\hat{y_i} = \sum_{j=1}^m \beta_jx_j.$$
Choosing the regression coefficients this way ensures that the average distance between the observed gross demand and the predicted gross demand is kept as low as possible, thus reducing the uncertainty in its predictions. The main challenge of this investigation was the choice of covariates to use, thus we tested several models, with different covariates. To compare their performance, we employed a measure of the portion of total variability explained by the model, $R^2$, defined as follows:
$$R^2 = 1 - \dfrac{\sum_{i=1}^n(y_i - \hat{y_i})^2}{\sum_{i=1}^n(y_i - \bar{y})^2},$$
where $y_i$ and $\hat{y_i}$ are as defined previously, and $\hat{y}$ is the mean of all observations of the gross demand.
We then constructed a $k$-fold cross validation scheme, to assess the performance of different models on unseen data. The cross validation scheme works by splitting the observations into $k$ groups of equal size, and using one of the groups to train the model, that is to determine the regression coefficients. With the coefficients fixed, the remaining $k-1$ groups are used to test the model, computing the value of $R^2$. The process is repeated $k$ times, training the model with a different group of each time, and computing the value of $R^2$ using the remaining groups. In the next section, we explore trends in the data as well as the baseline model provided, which is used as the starting point in our analysis.

# Data description and exploratory analysis
```{r Section 2 instructions, echo = FALSE}
#Emphasis should be placed on the data features that are relevant for the subsequent modeling. Include visualizations that #help illustrate key patterns or relationships. All plots must also be described in the write up. Think carefully about #whether each plot needs to be included in your final draft. Your report should include figures and tables but they should #be as focused and impactful as possible.

#Clearly describe all preprocessing steps, including any transformations or new variables created. If the additional #dataset (`SCS_hourly_temp.csv` ) is used, provide a concise explanation of its structure and relevance to the analysis.
```

## Data visualization and pre-processing
To prepare our data for analysis, we began by dropping unneeded coefficients. This was a list that changed over the course of our improvements on our candidate model, as we made informed changes to our model versions. Below is an initial covariate matrix that we used to get an overview of which columns could provide information on our response variable.

```{r covariate_matrix, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 1: Correletion matrix for all variables in the dataset SCS_demand_modelling.csv.'}
numeric_vars <- SCS_demand_modelling %>%
  select(-1, -Date)

#Correlation matrix
cor_matrix <- cor(numeric_vars, use = "pairwise.complete.obs")

# Create a more readable table with rounded values
cor_table <- round(cor_matrix, 3)

# Reshape the correlation matrix for ggplot
cor_data <- melt(cor_matrix)

# Create heat-map with ggplot2
heatmap <- ggplot(data = cor_data, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                        midpoint = 0, limit = c(-1,1), name = "Correlation") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_fixed() +
  geom_text(aes(label = round(value, 2)), size = 3) +
  labs(title = "Correlation Matrix for Demand Variables",
       x = "", y = "")

heatmap

```
<div style="height: 10px;"></div>
Firstly what we see from this plot is that there are many variables that have exceptionally high correlation. Inspecting which pairs these are, we observe that many of these are defined as transformations of one another, which explains their exceptionally high correlation. A major example of this is the "TO" and "TE" relationship.

We can see that the "year" variable has a moderate positive correlation to "demand_gross", and both "TO" and "TE" have a moderate negative correlation. These are some examples of how we might choose candidate models in order to improve upon the baseline model. 
The following plots; Figure 2, Figure 3, Figure 4 and Figure 5 provide insight on the precise nature of the relationship between gross demand and year, month, day and temperature respectively. These plots were instrumental in informing our choice of model.

```{r demand_vs_year, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figre 2: Plot of average yearly gross demand against year, highlighting their non-linear relationship.'}
SCS_demand_modelling <- SCS_demand_modelling %>%
  mutate(Date = as.Date(Date, format = "%Y-%m-%d"))

# Aggregate data for yearly average
demand_yearly <- SCS_demand_modelling %>%
  group_by(year) %>%
  summarise(avg_demand = mean(`demand_gross`, na.rm = TRUE))

# Plot: Yearly Average Gross Demand vs. Year
ggplot(demand_yearly, aes(x = year, y = avg_demand)) +
  geom_point(color = "darkblue") +
  geom_smooth(color = "darkred") +
  labs(title = "Yearly Average Gross Demand vs. Year",
       x = "Year", y = "Average Gross Demand (MW)") +
  theme_minimal()
```
<div style="height: 10px;"></div>
From the plot presented above, we observe a strong relationship between the year and the demand. We plotted average gross demand as solely a function of year, thus we initially conjectured some cyclical or polynomial relationship. However, the plot we observe here is sufficient for us to confidently include year as a covariate in our candidate models going forwards.

```{r demand_vs_month, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 3: Bar plot of average monthly gross demand against month, for the months of January(0), February(1), March(2), November(10) and December(11). This highlights the significant difference between March and the other months.'}

SCS_demand_modelling %>%
  group_by(monthindex) %>%
  summarize(avg_demand = mean(demand_gross, na.rm = TRUE)) %>%
  ggplot(aes(x = monthindex, y = avg_demand)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  labs(title = "Average Demand by Month",
       x = "Month Index", y = "Average Demand")
```
<div style="height: 10px;"></div>
As the number of data points on the month scale was sufficiently low, in the previous plot we chose to use a bar plot instead of treating the time scale as continuous.

The most visible result here is the difference between the month of March and the other months, with the month of March exhibiting lower average monthly gross demand than the other months. Qualitatively we can expect this, as March would be expected to be different in terms of weather to the other months for which we have data. It is reasonable to expect this to translate into a lower gross demand during this time.

```{r demand_vs_day, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 4: Bar plot of average gross demand against day, for the days of the week, that is Sunday(0), Monday(1), Tuesday(2), Wednesday(3), Thursday(4), Friday(5) and Saturday(6). This highlights the difference between weekend days(Sunday and Saturday) and the other days.'}
SCS_demand_modelling %>%
  group_by(wdayindex) %>%
  summarize(avg_demand = mean(demand_gross, na.rm = TRUE)) %>%
  ggplot(aes(x = wdayindex, y = avg_demand)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  theme_minimal() +
  labs(title = "Average Demand by Day of Week",
       x = "Day of Week Index", y = "Average Demand")
```
<div style="height: 10px;"></div>
Similarly to the month case, the above plot shows that there is a noticeable difference between the average gross demand of weekend days and weekdays. This is expected, as during weekends energy demand towards office lighting and heating, as well as commuting is lower, as a significant portion of the population does not work. 

```{r temp_demand, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 5: Scatter plot of gross demand against population weighted average tmeperature, showing a significant negative correlation.'}
ggplot(SCS_demand_modelling, aes(x = temp, y = demand_gross)) +
  geom_point(alpha = 0.3) +
  geom_smooth(method = "loess", color = "red") +
  theme_minimal() +
  labs(title = "Relationship Between Temperature and Demand",
       x = "Temperature", y = "Gross Demand")

```
<div style="height: 10px;"></div>
A reasonable assumption would be to expect energy demand to decrease with temperature, as the energy required to heat homes is reduced. Indeed the plot above supports this intuition, showing a negative correlation, although relatively weak between the two variables.

## Baseline model
The baseline model is the model used as a benchmark for all following models, it is given by:
$$Y_i = \beta_0 + \beta_1\text{wind}_i + \beta_2\text{solar}_i + \beta_3\text{temp}_i + \beta_4\text{wdayindex}_i + \beta_5\text{monthindex}_i + \epsilon_i.$$
This model does not perform well, moreover, its performance is highly dependent on the month, year and day of the observation. (ADD REFERENCE TO CROSS-VALIDATION RESULTS). This hints at the need to explore the relationship between gross demand and year, as well as refine the relationship between gross demand and "wdayindex" and "monthindex", as simply using a linear relationship for the previous two variables does not seem appropriate.

## New variables
In light of the weaknesses of the baseline model, we have created new covariates from the dataset, by appropriate transformations of existing variables, in an attempt to better capture their relationship with gross demand. The relationship displayed in figure (ADD REFERENCE) suggests the need to make a distinction between weekends and weekdays. To do so, we created a categorical variable "is_weekday", defined below:
$$\text{is_weekday}_i = \begin{cases} 1 & \text{if } i\text{ is a weekday} \\ 0 & \text{if } i\text{ is a weekend day}\end{cases}.$$
Similarly, we created another categorical variable, "is_winter", defined as follows:
$$\text{is_winter}_i = \begin{cases} 0 & \text{if } i\text{ is in March} \\ 1 & \text{otherwise}\end{cases},$$
as figure (ADD REFERENCE) shows that gross demand in March differs significantly from any other month. Figure (ADD REFERENCE) indicates that a linear relationship between gross demand and year is not suitable. As a result, we constructed a new variable instead, "year_d" to model the dependence of gross demand on the year, this was defined as follows:
$$\text{year}_{d_i} = |\text{year}_i - 2005|.$$
Finally, to capture the effects of the variability of the temperature in a given day, we defined the variable "daily_var", as displayed below:
$$\text{daily_var}_i = \widehat{Var}(\text{temp}_i) = \dfrac{1}{23}\sum_{j=1}^{24}(\text{temp}_{i,j} - \overline{\text{temp}_i})^2 .$$
This information was extracted from the "SCS_hourly_temp" dataset, and $\widehat{Var}(\text{temp}_i)$ is the estimated variance of all hourly temperature measurements from day $i$, $\overline{\text{temp}_i}$ is the average hourly temperature of day $i$, and $\text{temp}_{i,j}$ is the temperature recorded at day $i$ and hour $j$. The use of this dataset provides further insight of the relationship between gross demand and temperature, allowing our model to predict the former more accurately than if we had used temperature alone.

# Model fitting and cross-validation results
```{r Section 3 intsructions, echo = FALSE}
#In this section you should detail your choice of model and describe the process used to refine and fit the model. You are #encouraged to explore different models methods but you should not include a detailed narrative of all of these attempts. #For instance, you can mention the approaches you tried tried and include a comparison but do not add in depth discussions #of these models beyond why they were rejected. This section should mention the methods explored and why they were #rejected, but most of your effort should go into describing the model you are using and your process for tuning and #validating it.

#Provide implementation details and include results from cross-validation or other model evaluation techniques, #highlighting improvements and any trade-offs.
```

## Model overview
We are now ready to introduce our model, which builds on the baseline model, while incorporating the new variables defined in the previous section, as following:
$$Y_i = \beta_0 + \beta_1\text{Wind}_i + \beta_2\text{Solar}_i + \beta_3\text{temp}_i + \beta_4\text{is_weekday}_i + \beta_5\text{is_winter}_i + \beta_6\text{year_d}_i + \beta_7\text{TE}_i + \beta_8\text{daily_var}_i + \epsilon_i.$$
The model was fit using the "lm" built in function, which takes parameters "formula", which specifies the form of the linear model, in our case simply $Y \sim \text{Solar} + \text{Wind} + \text{week_type} + \text{season} + \text{year_d} + \text{Temp} + \text{TE} + \text{daily_var}$, and "data", which specifies which set of observations should be used to fit the model. The function then fits the model by computing the regression coefficients that minimize the value of $R^2$, as explained in the introduction.
This model performs better than most of the other models we have tested, with the main trade off being its increased complexity. To select this model, we have tested several variations including the use of different variables, or transformations of the variables. Although slightly better results were obtained for some models, for example by implementing a dependency on the cubic root of the temperature, justified by plot (ADD REFERENCE), they were ultimately discarded, as the slight improvement in prediction accuracy was not enough to justify the significant increase in model complexity.

## Model performance
```{r base_cross_validation, echo=FALSE, eval=FALSE}
source("code.R")

M0_cv <- k_fold_cross_validate(Model_M0, df, strat_vars = c("is_weekday", "is_winter"))
M5_cv <- k_fold_cross_validate(Model_M5, df, strat_vars = c("is_weekday", "is_winter"))


```

We use the function "k_fold_cross_validation()" to assess our model performance. The function works by splitting our data into k disjoint groups called 'folds'. Crucially because we have categorical variables present, we use stratified k-fold cross validation, which means that we keep the relative frequencies of each category present within each fold. This ensures that no fold is left with only one category level, and so therefore the model may always arrive at a coefficient for the categorical variable.

We then assess the model's performance via RMSE, $R^2$ and $adj-R^2$ across all remaining $k-1$ folds. This value is then stored, and the process is repeated with the model being refitted on each of the $k$ folds. The average of each of these metrics is computed and returned in the output of the function. 

For the baseline model discussed earlier, we note these key metrics. The overall adjusted $R^2$ metric is 0.06807436, which decreases slightly to 0.06134473 for the average adj-$R^2$ over each of our 5 folds. This model does not explain very much of the variation in the gross demand and therefore there is a lot of room for improvement.

Our model, M5, has an overall adjusted $R^2$ of 0.7616418 and a fold-average of 0.7579201.The plot below compares these figures as well as the RMSE of each model. 

```{r compare_metrics, echo=FALSE}


#make a dataframe from the output of the cro
overall_metrics <- data.frame(
  metric = c("RMSE", "R²", "Adjusted R²"),
  M0 = c(4824.76, 0.066, 0.060),
  M5 = c(2434.37, 0.762, 0.759)
)

# Reshape data for ggplot
overall_long <- overall_metrics %>%
  pivot_longer(cols = c(M0, M5), names_to = "model", values_to = "value")

# Create the faceted comparison plot (with appropriate scales)
p1_faceted <- overall_long %>%
  ggplot(aes(x = model, y = value, fill = model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  geom_text(aes(label = ifelse(metric == "RMSE", 
                               sprintf("%.0f", value), 
                               sprintf("%.3f", value))),
            position = position_dodge(width = 0.9), vjust = -0.3, size = 3.5) +
  scale_fill_manual(values = c("M0" = "#8884d8", "M5" = "#82ca9d")) +
  facet_wrap(~ metric, scales = "free_y") +
  theme_minimal() +
  labs(title = "M0 vs M5 Model Performance Comparison",
       subtitle = "Overall Performance Metrics",
       x = "",
       y = "Value",
       fill = "Model") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        plot.subtitle = element_text(hjust = 0.5),
        strip.background = element_rect(fill = "lightgray", color = NA),
        strip.text = element_text(face = "bold"))

# Monthly performance data - with months in chronological order
month_data <- data.frame(
  month = c("November", "December", "January", "February", "March"),
  M0_RMSE = c(4416.87, 5433.03, 4980.17, 4343.80, 4834.34),
  M5_RMSE = c(1369.95, 4080.94, 2389.46, 1453.45, 1742.50),
  M0_R2 = c(-0.010, 0.023, -0.085, 0.033, -0.148),
  M5_R2 = c(0.903, 0.449, 0.750, 0.892, 0.851)
)

# Set month as a factor with levels in chronological order
month_data$month <- factor(month_data$month, 
                          levels = c("November", "December", "January", "February", "March"))

# Reshape monthly RMSE data
month_rmse_long <- month_data %>%
  select(month, M0_RMSE, M5_RMSE) %>%
  pivot_longer(cols = c(M0_RMSE, M5_RMSE), 
               names_to = "model", 
               values_to = "RMSE") %>%
  mutate(model = gsub("_RMSE", "", model))

# Plot monthly RMSE
p2 <- ggplot(month_rmse_long, aes(x = month, y = RMSE, fill = model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  geom_text(aes(label = sprintf("%.0f", RMSE)),
            position = position_dodge(width = 0.9), vjust = -0.5, size = 3.2) +
  scale_fill_manual(values = c("M0" = "#8884d8", "M5" = "#82ca9d")) +
  theme_minimal() +
  labs(title = "Monthly Performance (RMSE)",
       x = "",
       y = "RMSE",
       fill = "Model") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1))

# Reshape monthly R² data
month_r2_long <- month_data %>%
  select(month, M0_R2, M5_R2) %>%
  pivot_longer(cols = c(M0_R2, M5_R2), 
               names_to = "model", 
               values_to = "R2") %>%
  mutate(model = gsub("_R2", "", model))

# Plot monthly R²
p3 <- ggplot(month_r2_long, aes(x = month, y = R2, fill = model)) +
  geom_bar(stat = "identity", position = position_dodge(width = 0.9), width = 0.8) +
  geom_text(aes(label = sprintf("%.3f", R2)),
            position = position_dodge(width = 0.9), vjust = ifelse(month_r2_long$R2 < 0, 1.5, -0.5), size = 3.2) +
  scale_fill_manual(values = c("M0" = "#8884d8", "M5" = "#82ca9d")) +
  theme_minimal() +
  labs(title = "Monthly Performance (R²)",
       x = "",
       y = "R²",
       fill = "Model") +
  theme(legend.position = "bottom",
        plot.title = element_text(hjust = 0.5, face = "bold"),
        axis.text.x = element_text(angle = 45, hjust = 1)) +
  ylim(-0.2, 1)

p1_faceted
p2
p3

```

## Compare winter
We investigated the variation in maximum demand over the winter of 2013/14, with the weather conditions from previous winters.

The function 'compare_winter' has been written for this task. We begin by selecting the data from the desired winter season. Then, we replace the year column with 2013/14 as appropriate, before redefining all of the year-dependent variables ('year_d, week_type') based upon this. Using the 'predict()' function from base R, we then predict the total demand over this fictional winter season before extracting and returning the maximum value that the model attains.

  
```{r compare_winter_plot_1, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 5: How Maximum Demand is Projected to Vary With Weather Conditions From Previous Years'}
source("code_modular.R")

years <- 1991:2012

comparisons <- lapply(years, function(year) {
  compare_winter(Model_M5, df, year)
})

comparisons_df <- data.frame(
  other_year = years,
  control_max = sapply(comparisons, function(x) x$control_max),
  max_predicted = sapply(comparisons, function(x) x$max_predicted)
)

comparisons_df <- mutate(comparisons_df, diff = (control_max - max_predicted))

# Plot 1: Predicted Max Demand
ggplot(data = comparisons_df, aes(x = other_year, y = max_predicted)) +
  geom_point() +
  geom_smooth(method = "loess", se = TRUE, color = "red") + # Added loess smoothing and removed standard error
  labs(
    title = "Predicted Max Demand If 2013/14 Had Another Winter's Weather",
    x = "Year Used for Weather Conditions",
    y = "Predicted Max Demand"
  ) +
  theme_minimal()
```
<div style="height: 10px;"></div>
```{r compare_winter_plot_2, echo=FALSE, message=FALSE, fig.align = 'center', fig.cap = 'Figure 6: How the Difference Between Projected Maximum Demand and Observed Maximum Demand Varies With Weather Conditions From Previous Years'}
# Plot 2: Predicted Difference
ggplot(data = comparisons_df, aes(x = other_year, y = diff)) +
  geom_point() +
  geom_smooth(method = "loess", se = TRUE, color = "blue") + # Added loess smoothing and removed standard error
  labs(
    title = "Predicted Difference in Max Demand If 2013/14 Had Another Winter's Weather",
    x = "Year Used for Weather Conditions",
    y = "Difference in Max Demand (Predicted - Actual)"
  ) +
  theme_minimal()
```
<div style="height: 10px;"></div>
These plots above depict both the predicted demand itself and the difference between it and the observed conditions in 2013/14.

The observed maximum demand over the winter of 2013/14 was 5243MW. From the difference plot, we can see that the difference is typically negative - most years' weather conditions would decrease the demand over the winter, our model predicts. We do see that there are several cases where the difference is positive, and that the predicted demand is higher than observed. However, the average difference is -262MW to the nearest MW.

A qualitative interpretation of this is that 2013/14 had a winter that caused an increase in demand for some number of factors. A reasonable first assumption could be that there was a lower average during this winter. We can check directly what the average temperature in the winter of 2013/14.

```{r check_temp, include=FALSE}

winter_set <- df |> 
    filter((year == "2013" & Month_Index %in% c(10, 11)) | (year == "2014" & Month_Index %in% c(0, 1, 2)))
 this_average <- mean(winter_set$Temp)
 
all_average <- mean(df$Temp)

print(this_average)
print(all_average)

```
Taking the average temperature over the 2013/14 winter we get 5.60 degrees (2dp.), as opposed to 4.77 degrees (2dp.) over the entire set. This is contrasting to our assumption, but there could be many reasons as to why the demand happened to be higher. This could be a potential limitation of the model, and we will discuss it in the dedicated section of this document.

# Conclusion
```{r section 4 instructions, echo = FALSE}
#Summarize here the key insights from your analysis, focusing on the final model’s predictive performance, reliability, and #practical relevance for NESO. Discuss the importance of the selected covariates, as well as any observed limitations or #assumptions that should be considered when applying the model in practice.

#Emphasize how your model can support NESO's long-term planning goals. If the model underperforms in some respects, provide #a clear and well-reasoned explanation. Keep in mind that a negative result, i.e. a model that does not work well #predictively, that is well explained and justified in terms of why it failed will likely receive higher marks than a model #with strong predictive performance but with poor or incorrect explanations and justifications. In other words, sound #reasoning and transparency will be valued more than overclaiming results.
```

Overall, our model performs well, and it achieves equally strong predictions in different time periods, with prediction accuracy being similar across all months and days of the week. A main limitation of the model is the relationship chosen between gross demand and "year". This is because the average yearly gross demand seems to increase steadily from 1991 to 2005, and then starts steadily dropping after 2005. The fact that the model was trained on only 10 years of data after 2005, makes it difficult to predict how the average yearly gross demand will behave in subsequent years. It could for example, start increasing again, thus making the period from 2005 to 2015 simply an exception to an otherwise linear trend. It could also be that the pattern is periodic, driven by the periodic nature of the economy. At the end we decided that average yearly gross demand is likely to continue dropping, driven by factors such as increased environmental awareness, increased availability and efficiency of renewable, non centralized sources and declining population growth. However the accuracy of our model's predictions in future years is strongly dependent on this relationship, which we cannot predict with confidence with the data given. As a result, the model's predictions are likely to become less accurate as the year of the observation strays further away from 2015. However, as long as the year of the observation is not too far from 2015, we expect the model to provide valuable and accurate insight on the gross demand. This means that our model will allow NESO to accurately predict future gross demand, provided that the model is not being used too far into the future(after 2015), allowing them to anticipate future changes in demand, and efficiently plan and allocate resources to ensure that the gross demand is reliably met. 

# Code Appendix
```{r section 5 instructions, echo = FALSE}
#Include here all the code used in your analysis. Ensure that the code is well-commented so it is easy to follow and reuse.
```
In this section, we provide the documentation for all the functions created and used in this report.

```{r code=readLines("code.R"), eval=FALSE, echo=TRUE}
# Do not change this code chunk
```

